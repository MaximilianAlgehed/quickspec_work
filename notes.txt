-- Motivation --

    As outlined in [QuickSpec 1&2, Conditional Lemma Discovery (Irene and Moa)] there is a need for
    QuickSpec to generate conditional equations. The need for conditional equations is motivated by
    two different use cases for QuickSpec. The first use case is QuickSpec as a Conjecture/Lemma discovery
    tool in use by other systems (Hipster). The second use case is QuickSpec as 
    a stand alone tool for proram specification and verification. In the first case conditional equations
    are necessary to prove certain algorithms correct. In the second case one of the more compelling
    reasons why we would want to find conditional equations in QuickSpec is the clean discovery of
    partial functions. There are more justifications outlined in the QuickSpec 1&2 papers.


-- Different methods for encoding constraints in QuickSpec --

    +: Function encoding (FE)

        Encode predicates as functions like so:

            p is the predicate

            p x = True

            whenP y 
                | p y       = y
                | otherwise = x

        For predicates of arity n there are two different approaches to whenP:

            whenP :: A -> B -> (A, B) -- arity approach

            whenP :: (A, B) -> (A, B) -- n-tuple approach

        Issues:

            Binary predicates create the issue where you have

            P x y => f x = g x

            Where x and y are in the predicate but y is not used

        Question, how to generate the value to return for which the predicate always holds at compile time?

    +: Type encoding: (TE)

        Create types that are instantiated such that some predicate always holds

        Positive result:
            Giving quickspec the insert (as in insertion sort) function, a type for 
            generating a pair of numbers (x, y) where x > y, and the basic list implementation
            (nil and cons) generates this rather exciting output in almost no time:

                insert i [] = i:[]
                insert x (y:is) = y:(insert x is)
                insert y (x:is) = y:x:is
            
            Conjunctions with relationships between the different sub-terms are just a "meta instance" of 
            normal TE (see Q-types).

        Issues:
            We get expressions like:

                x /= y => foo x = bar i j

            Where the predicate involves both x and y but the equation does not.

        There are three types in TE:
        
            P-types:

                P-types are the basic idea in TE

            Q-types

                Q-types represents two or more predicates which's free variables
                have some relation.

            T-types
                    
                T-types represent a predicate applied to a transformation (a mapping) of
                some data.
            
                T-types look like this

                    T x (t x)
                        where
                            x <- arbitrary `suchThat` (p . t) 

                Which, given fast generation of uniform constrained random data would be very fast.

        A general problem with TE is that the order of generating data is very bad. Consider the following
        example:

            x < y && y < z

        Represented roughly as:

            arbitrary (Q (P x y) (P y z)) = Q p1 p2
                suchThat
                    snd p1 == fst p2
                    where
                        fst p1 < snd p1
                        fst p2 < snd p2
        
        Here the order of the generation of the data is slow because we first generate p1 and p2 and then check
        that the second element of p1 is equal to the first element of p2.
        
        What we would like to do is to compute 
        an order that means that as few results as possible need to be recomputed.

        A novel algorithm that may work for this problem is the following:

            Given predicates and their arity, as well as all equality relations between variables. We
            can construct the Q-type with the order of generation and constraints on the generation
            constructed as so.

            1. Order all variables by their connectivity

            2. Pick the most connected variable as the next variable to be generated.

            3. Remove the selected variable from the list.

            4. Find all partialy applied predicates that when applied to the selected variable will be fully applied
               and generate the variable according to these predicates. If generation fails, backtrack.

            5. Find all predicates which will still be partially applied when applied to the variable, apply the predicates
               to the variable

            6. Go to 2 untill the list of variables is empty.

            7. All variables have been generated.

        An implementation of this algorithm shows promise for simple examples.
        
    +: Combined encoding (CE)

        Motivated by the inefficiency of generating constrained random data with uniform distribution faced by TE
        and the loss of soundness of having a go-to answer in FE we present the Combined Encoding (CE).

        In short CE is FE but with an extra argument, a TE representation of the predicate:

            whenP :: (A, B, Predicate A B) -> (A, B)
            whenP (x, y, z)
                | p x y = (x, y)
                | otherwise = z

        Becuase of haskell's call by need semantics this should work out more efficient than TE.

        The naive approach for transformations would be to use the transformation type 
        along with the n-tuple constructor.

    +: Comparison of TE, FE, and CE:

        -- Efficiency -- 
            *: FE
                An issue with FE is that when we introduce functions of higher airity (e.g. max and min) to 
                encode the predicates we get exponential blowup. Especially as we increase the maxTermSize.

                Interestingly we only have issues with blowup for non-unary predicates when we choose an FE
                encoding like so:
                    
                    whenP :: a -> b -> ... -> (a, b, ... )

                However the following encoding:

                    whenP :: (a, b, ... ) -> (a, b, ... )

                Greatly reduces the blowup.

                The reason why we don't get blowup when we encode using n-tuples is that there is no way to produce
                an n-tuple (there is no constructor for n-tuples).

                If we were to add a constructor for n-tuples into the signature we would get exponential blowup once again.

            *: TE
                One of the problems with TE is the issue of generating constrained random data with uniform distribution
                outlined by Koen's paper. TE will only become fast if this problem can be solved efficiently.

            *: CE
                CE tries to fix the issue of generating contrained random data with uniform distribution by
                using FE for "as long as possible". The issues faced by FE remain but the inefficencies faced
                by TE are minimized.

            *: Empirical data
                FE for maps, maxTermSize = 10
                    == Statistics ==
                    43855 events created in total (226 schemas, 9397 terms, 31596 creation, 2636 miscellaneous), 28 hooks.
                    14241 schema test cases for 210 representative schemas.
                    160563 term test cases for 9314 representative terms.
                    16 equal schemas and 83 equal terms generated.
                    200 rewrite rules, 0 extra rewrite rules.

                TE for maps, maxTermSize = 10
                    == Statistics ==
                    41027 events created in total (95 schemas, 8591 terms, 29958 creation, 2383 miscellaneous), 25 hooks.
                    1792 schema test cases for 84 representative schemas.
                    166903 term test cases for 8405 representative terms.
                    11 equal schemas and 186 equal terms generated.
                    211 rewrite rules, 0 extra rewrite rules.

                The differences in execution time for small examples is limited and the ordering
                is as expected FE < CE < TE. Where the difference between CE and TE is much greater than
                the difference between FE and CE.

        -- Conjunction -- 
            *: TE

                Let's say we have some binary (this is not a precondition, it simplifies the example)
                predicate type P.
        
                    data P = P {x::A, y::B}
                    instance Predicateable A B where
                        predicate = p

                If we introduce a function

                    eq_xy :: P -> P -> Bool
                    eq_xy p1 p2 = x p1 == y p2
                
                And we generate the binary (again, it is only binary for the sake of this example) type Q

                    data Q = Q {x'::P, y'::P}
                    instance Predicateable P P where
                        predicate = eq_xy

                Then QuickSpec can generate laws like:

                    f (y (x' q)) = g (x (y' q))

                which would correspond to:

                    (p a y) && (p x a) => f y = g x

                N-ary Q-types would allow for the same variable to exist in several different predicates,
                creating a conjunction of N terms.

                Furthermore it is conceivable that the Q type does not have to be predicateable over equality.
                Any relation between terms could be used.

                The algorithm proposed in the explanation of TE would allow Q-types over the Equality relation
                to be relatively fast compared to the novel way of implementing Q types discussed above.
                
            *: FE
                
                P x && Q x => x <*> y = ...
                gets encoded as
                ((Q'. P') x) <*> y = ...
                where Q' and P' are the function encodings of P and Q.
                However one would need to be very carefull when construction the functions
                Q' and P'. To see an example of how difficult this is notice:
                    
                    Q = not . null
                    P = sorted

                The naive implementation of Q' and P' would be:

                    Q' = whenNotNull
                    whenNotNull [] = [x] -- for some "representative" x
                    whenNotNull xs = xs

                    P' = whenSorted
                    whenSorted xs 
                        | isSorted xs = xs
                        | otherwise = []

                Which is completely fine (when considering only sorted and (not . null)).

                The problem is, what if we were to choose whenNotNull [] = [2, 1].
                Now we have whenSorted . whenNotNull /= whenNotNull . whenSorted.
                Also, the result isnt sorted in the second example.

                This is not a problem with this example, as [2, 1] is a truly bad choice of 
                representative. But if we have something like:

                    allNumbersInListLessThanZero

                    and

                    allNumersInListGreaterThanZeroOrZero

                Now we don't have any implementation of whenNotNull that does not exclude
                one predicate or the other.

                One approach for solving this problem would be to construct functions from all predicate functions
                where the predicate always holds. For an instance:

                    allNumbersInListLessThanZero_and_notNull
                
                This is kind of fine. But we now have an explosion of the size of the signature.

                In conclusion, the composition of these predicate functions does not work as a solution
                to the problem of conjunction. The alternative, to introduce some "power-set" of functions
                and construct additional functions from that set solves the problem of conjunction. 

        -- Soundness -- 
            Soundness is directly related to how uniform the test data is.

            FE risks losing soundness as predicates which rarely hold will be replaced by their
            "representative". As an example consider "reverseSortedAndLongerThan1000" for lists (this is a stupid example I know),
            this predicate will very rarely hold and if the representative is [] then maybe we discover laws about
            [] that are not about reverseSorted lists. The solution to this is "more testing", maybe...

            CE is a good approach for fixing this soundness issue (?).

        -- Transforms -- 
            In order to encode equations like the following:
                
                sorted (reverse xs) => ... xs ... (reverse xs) ... (1)

            One could imagine a representation like:

                ... xs ... (whenSorted (reverse xs)) (2)

            Sadly it turns out that the two representations are not the same and
            more specifically the FE representation in (2) can not be reduced to (1).

            However this can also be expressed in TE, but we need to change the type 
            so that it generates the transformed data and the other data at the same time (T-types).
            This way it would be accesed in this way:

                (x p) (xt p)

            Where (x p) would give the normal data and (xt p) would give the transformed data.

            This would however risk giving us annoying transform-types like:
                
                (xt p) == reverse . reverse 

            In order to avoid this one could imagine running QuickSpec twice. Once with the signature without
            transforms and once more with the transforms that are interesting, pruning away transforms like
            "id . reverse" and replacing them with "reverse".

            As mentioned in Irenes thesis there is a very real exponential blowup when we start considering 
            even finite size transforms.
            
            Transforms are only interesting if the equations contain x and the predicate concerns the transform of x.

            Transforms in FE are more difficult for arity > 1 functions. As outline below, if the n-tuple
            constructor is added the completeness of FE is negatively impacted.

            Transforms in FE are actually not as straight forward as they may seem. Consider the following example:
                
                whenPalindrome :: [A] -> [A]
                whenPalindrome xs 
                    | isPalindrome xs = xs
                    | otherwise      = [0]

            One would expect the following to hold:

                isPalindrome (reverse xs) => xs == (reverse xs)

            Which is expressed by the following equation:
                
                (whenPalindrome (reverse xs)) == xs

            Which is of course not true.
            
            Of course in the above example QuickSpec would find the equation:

                reverse (whenPalindrome xs) == whenPalindrome xs

            instead. However this may not always be the case.

            Another example:
                
                Consider the following constrained equation where xs is a non-null list: (non-null for technical reasons) 

                    sorted (tail xs) => insert (head xs) (tail xs) == sort xs

                To represent it in FE:

                    We use the when function:

                        when_sorted xs
                            | sorted xs = xs
                            | otherwise = []

                    To hope to generate the following equation:

                        insert (head xs) (when_sorted (tail xs)) == sort xs

                    However, this equation can not be generated, as:

                        insert (head [1, 3, 2]) when_sorted (tail [1, 3, 2]) =
                        insert 1 (when_sorted [3, 2]) = 
                        insert 1 [] =
                        [1]

                        sort [1, 3, 2] = [1, 2, 3]

                        [1] =/= [1, 2, 3]

                To represent it in TE:

                    In T-types the predicate (sorted) is true for the transform of the original
                    data. So in here we have:

                        tsortedtail = Tsorted xs tail_xs
                            => (tail xs) == tail_xs && sorted (tail_xs)
                        insert (head (xs tsortedtail)) (tail_xs tsortedtail) == sort (xs tsortedtail)

        -- Completeness --
            In order to discuss completeness with regards to expressions that do involve implications
            it would be usefull to consider the increase in terms size needed to generate an expression
            on the form:

                P x y ... => E_z[x, y, ... ]

            Where E_z[x, y, ... ] is any equation that would have been considered by old QuickSpec for a given 
            term size z.

            Neither strategy negatively impacts completeness for expressions not involving
            implications as any equations which would be generated
            without FE or TE will still be generated with FE or TE in place. Both methods simply add
            to the existing coverage of QuickSpec. 

            For TE the impact on completeness is linear by a factor 1 in the number of variable occurances in E_z.
            This is because any variable i in E_z could be replaced by (x p) where p is a predicate and x
            is a variable in that predicate. This however is only true for predicate types. For Q-types
            the size increase is a factor 2 in the number of variable occurances in E_z. However, this factor 2 can 
            be reduced to 1 if the access functions from Q-types to the variable types are combined.

            For FE the impact on completeness is dependent on the implementation. It is possible to make the overhead
            linear by a factor 1 in the number of variable occurances in E_z. This is done by having multiple when-functions
            per predicate: 
                
                whenP :: (a, b) -> (a, b)

                fstwhenP = fst . whenP
                sndwhenP = snd . whenP

            However, completeness extends beyond the size of the expressions. There are equations which
            FE and CE can't find but TE can. These equations are primarily the ones which require predicates
            of transforms.

    +: Automatic generation of TE types from given predicates:

        We find that the predicate (sorted :: (Ord a) => [a] -> Bool) can be replaced by a type for sorted lists.

        In fact any unary predicate over some type T:
            
            predicate :: T -> Bool

        Can be modelled as a type:

            data Predicate = Predicate T

            instance Arbitrary where
                arbitrary = fmap Predicate $ arbitrary `suchThat` predicate

        This gives us a conversion from unary FE to unary TE.

        Similary for a binary predicate over any two types T and T':

            predicate :: T -> T' -> Bool

        Can be modelled as the type:

            data Predicate = Predicate T T'

            instance Arbitrary Predicate where
                arbitrary = do
                                (t, t') <- suchThat arbitrary (\(x, y) -> p x y)
                                return (Predicate t t')

        It is important to note that this construction allows encoding of a predicate as a type, in the sense that
        it let's us constuct propositions like P(x) -> E, or !P(x) -> E, where E is an expression (or in the case of
        quickspec an equality). However, it does not let us discover neat laws about the predicate.

        More generally what we can do is something hacky like this:

            class Predicatable a where
                getPredicate :: a -> Bool
            
            predicate :: A -> Bool

            instance Predicatable A where
                getPredicate = predicate

        Now we can derive:

            newtype Predicate a = P a

            instance (Predicatable a, Arbitrary a) => Arbitrary (Predicate a) where
                arbitrary = return . P =<< arbitrary `suchThat` getPredicate

        An example of this is in the derived_predicate demo.

        Even more generally, using template haskell, we can generate these instances for any arity.

    +: Notes on theorem proving

        The TeExamples/NotNill.hs example is a wonderfull example of why case analysis in QuickSpec's pruning would be good:

            When given the predicate "NotNull" and its negation over lists QuickSpec finds a few different equations:

                [] ++ is = is
                head (i : is) = i
                NotNull xs => head (xs ++ is) = head xs
                not (NotNull xs) => xs = []
            
            which along with:

                P or (not P)

            would let us prove:

                head (is ++ (i : js)) = head (is ++ (i : is))

            as: (Natural deduction esque proof)

                (NotNull is) or (not (NotNull is))
                [(NotNull is)
                 head (is ++ (i : js)) = head is
                 head (is ++ (i : is)) = head is
                 head (is ++ (i : js)) = head (is ++ (i : is))
                ]
                [(not (NotNull is))
                 is = []
                 head (is ++ (i : js)) = head (i : js) = i
                 head (is ++ (i : is)) = head (i : is) = i
                 head (is ++ (i : js)) = head (is ++ (i : is))
                ]
                head (is ++ (i : js)) = head (is ++ (i : is))
        
            however, because QuickSpec does not deal with simple case analysis 
            it still prints:

                head (is ++ (i : js)) = head (is ++ (i : is))


-- Methodology --

    *: Methodology for comparison of FE, TE, and CE
        There are several qualities by which we measure the performance of FE and TE.
        Some of the things discussed in the section above are:

            ~ Efficiency
            ~ Soundness
            ~ Completeness
            ~ Power, i.e. Conjunction and Transforms
            ~ Generality

        These qualities are usefull and relevant as they influence 
        the usefullness of QuickSpec as a conjecture generating
        component in HipSpec and as a stand-alone tool:

            +: Efficiency 
            Efficiency is highly relevant when working with intractable problems like
            the ones QuickSpec encounters.

            +: Soundness
            Soundness is a big issue, it can directly influence the efficiency of systems that use 
            QuickSpec. Soundness is also relevant for anyone who is using QuickSpec to explore
            a set of functions (like in the case studies in the papers).

            +: Generality
            Generality is important as it can help write automated tools that incorporate QuickSpec.
            Without a general method for finding FE or TE representations of predicates
            it is difficult to imagine an automated tool that uses predicates in QuickSpec extensively.

            +: Completeness
            Completeness is of interest for the reason pointed out in the first paper on QuickSpec that
            missing equations teaches the user as much about the systems as the equations which are
            present. For this reason the higher the degree of completeness the higher the usefullness
            of QuickSpec as a stand-alone tool. It can be argued that completeness is not as important from an
            integration into other systems point of view as those systems can be left to "fill in the blanks".
            However, if QuickSpec is incomplete then it also directly loses power as a sub-system.
            
            +: Power
            The power of QuickSpec is directly related to the completeness of QuickSpec.

        There are factors and qualities by which one could compare FE and TE which we have
        not explored:

            ~ Ease of implementation

        The reson these things were not considered in more detail are the following:

            +: Ease of implementation
            The primary motivation for this work is to increase the power of QuickSpec as a component
            in larger theorem proving systems. Therefore the implementation specific details are 
            highly dependent of the implementation of such tools.


-- Improvements on old QS --

    +: Invariants
        
        Good results have been obtained when running QuickSpec with TE on 
        datatypes which have invariants. There are several equations about efficient
        functional queues that obey the invariant described in "The fun of programming"
        that QuickSpec is now capable of discovering.

    +: Generally

        In general every example that we have studied have yielded non-trivial conditional equations 
        that QuickSpec was unable to discover before. A personal favourite is the entire 
        implementation of Insertion sort (which is not relly non-trivial as it can be obtained from looking
        at the implementation of insert and insertion sort I suppose...).


-- Injectivity --

    When trying to prove injectivity of a pretty printer for arithemtic expressions one
    finds oneself needing the following predicate and associated conditional equation:
        
        P(e, f, s, t) := showTerm e ++ s = showTerm f ++ t (1)
        P(e, f, s, t) => e = f && s = t (2)
    
    When adding P to the signature of QuickSpec however, the tool grinds to a complete halt. This is
    because, as we can see in (2), generating data where P holds implies generating two
    random expression which are equal, and generating two random strings which are also equal.

    The problem here is that showTerm and the partially applied append function are both injective.
    Predicates involving injective functions generaly don't fare well in a normal TE setting. However,
    they also don't fare well in a FE setting, in FE they lose soundness big time.

    One idea for how to deal with injective functions is to let the user specify that they suspect that 
    a function may be injective. Which would then let us write a generator that is more likely to generate
    equal data. One could even imagine having a generator which chooses between arbitrary data
    and data which is very likely to be equal, this way cornercases where the function is not injective may
    still be found.


-- Comparison to other work --

    +: Automatic induction inside superposition

        QuickSpec now automatically finds the conjecture:
            
            length xs = length ys => zip (reverse xs) (reverse ys) = reverse (zip xs ys) 

    +: Hipster: Integrating theory exploration in a proof assistant

        QuickSpec now automatically finds the conjecture:
            
            xs /= [] => head (xs ++ ys) = head xs

        QuickSpec can now generate conditional equations to handle
        partial functions. This means that we have a new way to handle
        the "head" and "second" functions discussed in section 4 (?).


-- The bitvector example --

    This bitvector example can actually be generalized with conjunction, as it's really any number which is smaller
    than or equal to n. This should be talked about in the discussion of conjunction.

-- A programming language --

    There are several things that are made difficult by the shallow embedding. Maybe a deep embedding is needed.
    Cross-dimensional equality should help improve things. Lifting things from ⍴ to ⍴ 1 should be an opeation. (V.singleton)
    This should help QuickSpec


-- Future work --

    Automatic conjunction of predicates is a topic that should be worked on. The current implementation
    of the tool does not automatically find conjunctions. However looking at examples in datastructures
    we see that many equations have the form: invariant && predicate => equation.

    Efficient conjunction over many predicates is an interesting problem for which there are ideas floating 
    around that could prove good/bad. One idea is to reduce the variables in a set of conjoined predicates
    by the equalities present and then use the "degree of dependancy" of variables to order the generation.
    This along with some degree of randomness and (maybe) backtracking may prove usefull.


-- Related work --

    As of yet we don't have a clear list of related work. Most work on constrained equations deal with constrained equations
    in completion or (and) superposition. Which is not strictly we are trying to do
    (however, that research is usefull as it could be used 
    in conjunction with this work to help reason about the equations found by QuickSpec using our method).
    However, some work to mention is of course Moa and Irenes paper. Maybe mention that this has been done
    on a very small scale in the old quickspec papers (the monotonic function example comes to mind).


-- List of topics --

    *: Introduction
   
    *: Motivation

    *: Methodology

    *: TE
    
    *: FE

    *: CE

    *: Automatic generation

    *: Conjunction

    *: Transforms

    *: Efficiency

    *: Soudness

    *: Injectivity

    *: Conclusion 

    *: Future work

    *: Related work
