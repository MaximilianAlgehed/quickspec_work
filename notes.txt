-- Motivation --

    As outlined in [QuickSpec 1&2, Conditional Lemma Discovery (Irene and Moa)] there is a need for
    QuickSpec to generate conditional equations. The need for conditional equations is motivated by
    two different use cases for QuickSpec. The first use case is QuickSpec as a Conjecture/Lemma discovery
    tool in use by other systems (mainly Hipster and Isabelle). The second use case is QuickSpec as 
    a stand alone tool for proram specification and verification. In the first case conditional equations
    are necessary to prove certain algorithms correct. In the second case one of the more compelling
    reasons why we would want to find conditional equations in QuickSpec is the clean discovery of
    partial functions.


-- Different methods for encoding constraints in QuickSpec --

    +: Function encoding (FE)

        Encode predicates as functions like so:

            p is the predicate

            p x = True

            whenP y 
                | p y       = y
                | otherwise = x

        For predicates of arity n there are two different approaches to whenP:

            whenP :: A -> B -> (A, B) -- arity approach

            whenP :: (A, B) -> (A, B) -- n-tuple approach

        Issues:

            Binary predicates create the issue where you have

            P x y => f x = g x

            Where x and y are in the predicate but y is not used

        Question, how to generate the value to return for which the predicate always holds at compile time?

    +: Type encoding: (TE)

        Create types that are instantiated such that some predicate always holds

        Positive result:
            Giving quickspec the insert (as in insertion sort) function, a type for 
            generating a pair of numbers (x, y) where x > y, and the basic list implementation
            (nil and cons) generates this rather exciting output in almost no time:

                insert i [] = i:[]
                insert x (y:is) = y:(insert x is)
                insert y (x:is) = y:x:is
            
            Conjunctions with relationships between the different sub-terms are just a "meta instance" of 
            normal TE

        Issues:
            We get expressions like:

                x /= y => foo x = bar i j

            Where the predicate involves both x and y but the equation does not.

        There are three types in TE:
        
            P-types:

                P-types are the basic idea in TE

            Q-types

                Q-types represents two or more predicates which's free variables
                have some relation.

            T-types
                    
                T-types represent a predicate applied to a transformation (a mapping) of
                some data.
            
                T-types can be implemented like this:

                    T x (t x)
                        where
                            x <- arbitrary `suchThat` (p . t) 

                Which, given fast generation of uniform constrained random data would be very fast.

        A general problem with TE is that the order of generating data is very bad. Consider the following
        example:

            x < y && y < z

        Represented roughly as:

            arbitrary (Q (P x y) (P y z)) = Q p1 p2
                suchThat
                    snd p1 == fst p2
                    where
                        fst p1 < snd p1
                        fst p2 < snd p2
        
        Here the order of the generation of the data is slow because we first generate p1 and p2 and then check
        that the second element of p1 is equal to the first element of p2.
        
        What we would like to do is to compute 
        an order that means that as few results as possible need to be recomputed.

    +: Combined encoding (CE)

        Motivated by the inefficiency of generating constrained random data with uniform distribution faced by TE
        and the loss of soundness of having a go-to answer in FE we present the Combined Encoding (CE).

        In short CE is FE but with an extra argument, a TE representation of the predicate:

            whenP :: (A, B, Predicate A B) -> (A, B)
            whenP (x, y, z)
                | p x y = (x, y)
                | otherwise = z

        Becuase of haskell's call by need semantics this should work out more efficient than TE.

        The naive approach for transformations would be to use the transformation type 
        along with the n-tuple constructor.

    +: Comparison of TE, FE, and CE:

        -- Efficiency -- 
            *: FE
                An issue with FE is that when we introduce functions of higher airity (e.g. max and min) to 
                encode the predicates we get exponential blowup. Especially as we increase the maxTermSize.

                Interestingly we only have issues with blowup for non-unary predicates when we choose an FE
                encoding like so:
                    
                    whenP :: a -> b -> ... -> (a, b, ... )

                However the following encoding:

                    whenP :: (a, b, ... ) -> (a, b, ... )

                Greatly reduces the blowup.

                The reason why we don't get blowup when we encode using n-tuples is that there is no way to produce
                an n-tuple (there is no constructor for n-tuples).

                If we were to add a constructor for n-tuples into the signature we would get exponential blowup once again.

            *: TE
                One of the problems with TE is the issue of generating constrained random data with uniform distribution
                outlined by Koen's paper. TE will only become viable if this problem can be solved efficiently.

            *: CE
                CE tries to fix the issue of generating contrained random data with uniform distribution by
                using FE for "as long as possible". The issues faced by FE remain but the inefficencies faced
                by TE are minimized.

            *: Empirical data
                FE for maps, maxTermSize = 10
                    == Statistics ==
                    43855 events created in total (226 schemas, 9397 terms, 31596 creation, 2636 miscellaneous), 28 hooks.
                    14241 schema test cases for 210 representative schemas.
                    160563 term test cases for 9314 representative terms.
                    16 equal schemas and 83 equal terms generated.
                    200 rewrite rules, 0 extra rewrite rules.

                TE for maps, maxTermSize = 10
                    == Statistics ==
                    41027 events created in total (95 schemas, 8591 terms, 29958 creation, 2383 miscellaneous), 25 hooks.
                    1792 schema test cases for 84 representative schemas.
                    166903 term test cases for 8405 representative terms.
                    11 equal schemas and 186 equal terms generated.
                    211 rewrite rules, 0 extra rewrite rules.

                The differences in execution time for small examples is limited and the ordering
                is as expected FE < CE < TE. Where the difference between CE and TE is much greater than
                the difference between FE and CE.

        -- Conjunction -- 
            *: TE

                Let's say we have some binary (this is not a precondition, it simplifies the example)
                predicate type P.
        
                    data P = P {x::A, y::B}
                    instance Predicateable A B where
                        predicate = p

                If we introduce a function

                    eq_xy :: P -> P -> Bool
                    eq_xy p1 p2 = x p1 == y p2
                
                And we generate the binary (again, it is only binary for the sake of this example) type Q

                    data Q = Q {x'::P, y'::P}
                    instance Predicateable P P where
                        predicate = eq_xy

                Then QuickSpeck can generate laws like:

                    f (y (x' q)) = g (x (y' q))

                which would correspond to:

                    (p a y) && (p x a) => f y = g x

                N-ary Q-types would allow for the same variable to exist in several different predicates,
                creating a conjunction of N terms.

                Furthermore it is conceivable that the Q type does not have to be predicateable over equality.
                Any relation between terms could be used.

            *: FE
                
                P x && Q x => x <*> y = ...
                gets encoded as
                ((Q'. P') x) <*> y = ...
                where Q' and P' are the function encodings of P and Q.
                However one would need to be very carefull when construction the functions
                Q' and P'. To see an example of how difficult this is notice:
                    
                    Q = not . null
                    P = sorted

                The naive implementation of Q' and P' would be:

                    Q' = whenNotNull
                    whenNotNull [] = [x] -- for some "representative" x
                    whenNotNull xs = xs

                    P' = whenSorted
                    whenSorted xs 
                        | isSorted xs = xs
                        | otherwise = []

                Which is completely fine (when considering only sorted and (not . null)).

                The problem is, what if we were to choose whenNotNull [] = [2, 1].
                Now we have whenSorted . whenNotNull /= whenNotNull . whenSorted.
                Also, the result isnt sorted in the second example.

                This is not a problem with this example, as [2, 1] is a truly bad choice of 
                representative. But if we have something like:

                    allNumbersInListLessThanZero

                    and

                    allNumersInListGreaterThanZeroOrZero

                Now we don't have any implementation of whenNotNull that does not exclude
                one predicate or the other.

                One approach for solving this problem would be to construct functions from all predicate functions
                where the predicate always holds. For an instance:

                    allNumbersInListLessThanZero_and_notNull
                
                This is kind of fine. But we now have an explosion of the size of the signature.

                In conclusion, the composition of these predicate functions does not work as a solution
                to the problem of conjunction. The alternative, to introduce some "power-set" of functions
                and construct additional functions from that set solves the problem of conjunction. 

        -- Soundness -- 
            Soundness is directly related to how uniform the test data is.

            FE risks losing soundness as predicates which rarely hold will be replaced by their
            "representative". As an example consider "reverseSortedAndLongerThan1000" for lists (this is a stupid example I know),
            this predicate will very rarely hold and if the representative is [] then maybe we discover laws about
            [] that are not about reverseSorted lists. The solution to this is "more testing", maybe...

            CE is a good approach for fixing this soundness issue.

        -- Transforms -- 
            FE can potentially be more powerfull than TE, as an example it is capable of expressing:
                
                sorted (reverse xs) => ... xs ... (reverse xs) ...

            through equations like:

                ... xs ... (whenSorted (reverse xs)) 

            However this can also be expressed in TE, but we need to change the type 
            so that it generates the transformed data and the other data at the same time.
            This way it would be accesed in this way:

                (x p) (xt p)

            Where (x p) would give the normal data and (xt p) would give the transformed data.

            This would however risk giving us annoying transform-types like:
                
                (xt p) == reverse . reverse 

            To this end it would now be usefull to run QuickSpec on the signature without the 
            predicate types in it at first (maybe with some ad-hoc FE to "substitute" TE) and
            try to prove the equality of transforms.

            An advantage of FE here is clearly the fact that run-time generation (by QuickSpec)
            is a "solved" problem while a TE solution would require us to do something more 
            radical, like introduce a theorem prover at compile time (if we assume that
            the TE types are generated at compile time by template haskell). However this 
            theorem prover may not need to be so complex or general.

            Transforms are only interesting if the equations contain both x and the transform of x.
            Unless the transform significantly alters the structure of the expression, in a way which
            would be quantifiable by some predicate. However, then it would be more interesting to 
            just have the predicate type with that predicate.

            Transforms in FE ae more difficult for arity > 1 functions. As outline below, if the n-tuple
            constructor is added the completeness of FE is negatively impacted.

            Transforms in FE are actually not as straight forward as they may seem. Consider the following example:
                
                whenPalindrome :: [A] -> [A]
                whenPalindrome xs 
                    | isPalindrome xs = xs
                    | otherwise      = [0]

            One would expect the following to hold:

                isPalindrome (reverse xs) => xs == (reverse xs)

            Which is expressed by the following equation:
                
                (whenPalindrome (reverse xs)) == xs

            Which is of course not true.
            
            Of course in the above example QuickSpec would find the equation:

                reverse (whenPalindrome xs) == whenPalindrome xs

            instead. However this may not always be the case.

            Another more realistic example:
                
                Consider the following constrained equation where xs is a non-null list: (non-null for technical reasons) 

                    sorted (tail xs) => insert (head xs) (tail xs) == sort xs

                To represent it in FE:

                    We use the when function:

                        when_sorted xs
                            | sorted xs = xs
                            | otherwise = []

                    To hope to generate the following equation:

                        insert (head xs) (when_sorted (tail xs)) == sort xs

                    However, this equation can not be generated, as:

                        insert (head [1, 3, 2]) when_sorted (tail [1, 3, 2]) =
                        insert 1 (when_sorted [3, 2]) = 
                        insert 1 [] =
                        [1]

                        sort [1, 3, 2] = [1, 2, 3]

                To represent it in TE:

                    In T-types the predicate (sorted) is true for the transform of the original
                    data. So in here we have:

                        tsortedtail = Tsorted xs tail_xs
                            => (tail xs) == tail_xs && sorted (tail_xs)
                        insert (head (xs tsortedtail)) (tail_xs tsortedtail) == sort (xs tsortedtail)

        -- Completeness --
            In order to discuss completeness with regards to expressions that do involve implications
            it would be usefull to consider the increase in terms size needed to generate an expression
            on the form:

                P x y ... => E_z[x, y, ... ]

            Where E_z[x, y, ... ] is any equation that would have been considered by old QuickSpec for a given 
            term size z.

            Neither strategy negatively impacts completeness for expressions not involving
            implications as any equations which would be generated
            without FE or TE will still be generated with FE or TE in place. Both methods simply add
            to the existing coverage of QuickSpec. 

            For TE the impact on completeness is linear by a factor 1 in the number of variable occurances in E_z.
            This is because any variable i in E_z could be replaced by (x p) where p is a predicate and x
            is a variable in that predicate. This however is only true for predicate types. For Q-types
            the size increase is a factor 2 in the number of variable occurances in E_z. However, this factor 2 can 
            be reduced to 1 if the access functions from Q-types to the variable types are combined.

            For FE the impact on completeness is dependent on the implementation. It is possible to make the overhead
            linear by a factor 1 in the number of variable occurances in E_z. This is done by having multiple when-functions
            per predicate: 
                
                whenP :: (a, b) -> (a, b)

                fstwhenP = fst . whenP
                sndwhenP = snd . whenP


            However, completeness extends beyond the size of the expressions. There are equations which
            FE and CE can't find but TE can. These equations are primarily the ones which require predicates
            of transforms.

    +: Automatic generation of TE types from given predicates:

        We find that the predicate (sorted :: (Ord a) => [a] -> Bool) can be replaced by a type for sorted lists.

        In fact any unary predicate over some type T:
            
            predicate :: T -> Bool

        Can be modelled as a type:

            data Predicate = Predicate T

            instance Arbitrary where
                arbitrary = fmap Predicate $ arbitrary `suchThat` predicate

        This gives us a conversion from unary FE to unary TE.

        Similary for a binary predicate over any two types T and T':

            predicate :: T -> T' -> Bool

        Can be modelled as the type:

            data Predicate = Predicate T T'

            instance Arbitrary Predicate where
                arbitrary = do
                                (t, t') <- suchThat arbitrary (\(x, y) -> p x y)
                                return (Predicate t t')

        It is important to note that this construction allows encoding of a predicate as a type, in the sense that
        it let's us constuct propositions like P(x) -> E, or !P(x) -> E, where E is an expression (or in the case of
        quickspec an equality). However, it does not let us discover neat laws about the predicate.

        More generally what we can do is something hacky like this:

            class Predicatable a where
                getPredicate :: a -> Bool
            
            predicate :: A -> Bool

            instance Predicatable A where
                getPredicate = predicate

        Now we can derive:

            newtype Predicate a = P a

            instance (Predicatable a, Arbitrary a) => Arbitrary (Predicate a) where
                arbitrary = return . P =<< arbitrary `suchThat` getPredicate

        An example of this is in the derived_predicate demo.

        Even more generally, using template haskell, we can generate these instances for any arity.


-- Methodology --

    *: Methodology for comparison of FE, TE, and CE
        There are several qualities by which we measure the performance of FE and TE.
        Some of the things discussed in the section above are:

            ~ Efficiency
            ~ Soundness
            ~ Completeness
            ~ Power, i.e. Conjunction and Transforms
            ~ Generality

        These qualities are usefull and relevant as they influence 
        the usefullness of QuickSpec as a component in HipSpec and
        as a stand-alone tool:

            +: Efficiency 
            Efficiency is highly relevant when working with intractable problems like
            the ones QuickSpec encounters.

            +: Soundness
            Soundness is a big issue, it can directly influence the efficiency of systems that use 
            QuickSpec. Soundness is also relevant for anyone who is using QuickSpec to explore
            a set of functions (like in the case studies in the papers).

            +: Generality
            Generality is important as it can help write automated tools that incorporate QuickSpec.
            Without a general method for finding FE or TE representations of predicates
            it is difficult to imagine an automated tool that uses predicates in QuickSpec extensively.

            +: Completeness
            Completeness is of interest for the reason pointed out in the first paper on QuickSpec that
            missing equations teaches the user as much about the systems as the equations which are
            present. For this reason the higher the degree of completeness the higher the usefullness
            of QuickSpec as a stand-alone tool. It can be argued that completeness is not as important from an
            integration into other systems point of view as those systems can be left to "fill in the blanks".
            However, if QuickSpec is incomplete then it also directly loses power as a sub-system.
            
            +: Power
            The power of QuickSpec is directly related to the completeness of QuickSpec.

        There are factors and qualities by which one could compare FE and TE which we have
        not explored:

            ~ Ease of implementation

        The reson these things were not considered in more detail are the following:

            +: Ease of implementation
            The primary motivation for this work is to increase the power of QuickSpec as a component
            in larger theorem proving systems. Therefore the implementation specific details are 
            highly dependent of the implementation of such tools.


-- Future work --

    It would be nice to come up with a QuickSpec DSL in which we can express the subtelties of these constrained data
    in a way that would allow us to come up with optimal orders in which to generate the data.


-- Related work --

    As of yet we don't have a clear list of related work. Most work on constrained equations deal with constrained equations
    in completion or (and) superposition. Which is not what we are trying to do (however, that research is usefull as it could be used 
    in conjunction with this work to help reason about the equations found by QuickSpec using our method).


-- List of topics --

    *: Introduction
   
    *: Motivation

    *: Methodology

    *: TE
    
    *: FE

    *: CE

    *: Automatic generation

    *: Conjunction

    *: Transforms

    *: Efficiency

    *: Soudness

    *: Conclusion 

    *: Future work

    *: Related work?
