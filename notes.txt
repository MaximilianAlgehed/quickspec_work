*: people.mpi-inf.mpg.de/~dwand/datasup/draft.pdf
    Automatic Induction inside Superposition

-- Pros and cons of different methods for encoding constraints in QuickSpec --

    +: Function encoding (FE)

        Encode predicates as functions like so:

            p is the predicate

            p x = True

            whenP y 
                | p y       = y
                | otherwise = x

        For predicates of arity n the function whenP goes from an n-tuple to an n-tuple

        When doing this we need to add fst and snd to the signature.

        Negative results:
            
            Using the method of encoding predicates with airty > 1 as:
                whenP :: (a, b) -> (a, b)
            Doesn't work very well for disjoint sets as an example (as seen in the set_FE demo).

        Issues:

            Binary predicates create the issue where you have

            P x y => f x = g x

            Where x and y are in the predicate but y is not used

        Question, how to generate the value to return for which the predicate always holds at compile time?

    +: Type encoding: (TE)

        Create types that are instantiated such that some predicate always holds

        Positive result:
            Giving quickspec the insert (as in insertion sort) function, a type for 
            generating a pair of numbers (x, y) where x > y, and the basic list implementation
            (nil and cons) generates this rather exciting output in almost no time:

                insert i [] = i:[]
                insert x (y:is) = y:(insert x is)
                insert y (x:is) = y:x:is
            
            Conjunctions with relationships between the different sub-terms are just a "meta instance" of 
            normal TE

        Issues:
            We get expressions like:

                x /= y => foo x = bar i j

            Where the predicate involves both x and y but the equation does not.
        
    +: Things to figure out:

        *: Transformation types in TE (types where we generate a predicate that holds after some transform is applied to x)

        *: Injection functions to the types in TE. Is it really necessary? Can we get around it in the knuth bendix completion?

    +: Comparison of TE and FE:

        -- Efficiency -- 
            An issue with FE is that when we introduce functions of higher airity (e.g. max and min) to 
            encode the predicates we get exponential blowup. Especially as we increase the maxTermSize.

            Interestingly we only have issues with blowup for non-unary predicates when we choose an FE
            encoding like so:
                
                whenP :: a -> b -> ... -> (a, b, ... )

            However the following encoding:

                whenP :: (a, b, ... ) -> (a, b, ... )

            Greatly reduces the blowup.

            The reason why we don't get blowup when we encode using n-tuples is that there is no way to produce
            an n-tuple (there is no constructor for n-tuples).

            If we were to add a constructor for n-tuples into the signature we would get exponential blowup once again.

            A comparison of having max (which is not a pure FE encoding) versus having
            Greater (a TE encoding: newtype P = P {x::Int, y::Int}, (x p) >= (y p))
            for encoding the relation >=, both in the "foreground" theory:

                With max for insert with size 7:
                    1609 events 
                with max for insert with size 9:
                    33000 events
                With Greater for insert with size 7:
                    990 events
                With Greater for insert with size 9:
                    11000 events

            Another example of TE vs. FE:

                FE for maps, maxTermSize = 10
                    == Statistics ==
                    43855 events created in total (226 schemas, 9397 terms, 31596 creation, 2636 miscellaneous), 28 hooks.
                    14241 schema test cases for 210 representative schemas.
                    160563 term test cases for 9314 representative terms.
                    16 equal schemas and 83 equal terms generated.
                    200 rewrite rules, 0 extra rewrite rules.

                TE for maps, maxTermSize = 10
                    == Statistics ==
                    41027 events created in total (95 schemas, 8591 terms, 29958 creation, 2383 miscellaneous), 25 hooks.
                    1792 schema test cases for 84 representative schemas.
                    166903 term test cases for 8405 representative terms.
                    11 equal schemas and 186 equal terms generated.
                    211 rewrite rules, 0 extra rewrite rules.

        -- Conjunction -- 
            *: In TE we can do conjunction in the following way:

                Let's say we have some binary (this is not a precondition, it simplifies the example)
                predicate type P.
        
                    data P = P {x::A, y::B}
                    instance Predicateable A B where
                        predicate = p

                If we introduce a function

                    eq_xy :: P -> P -> Bool
                    eq_xy p1 p2 = x p1 == y p2
                
                And we generate the binary (again, it is only binary for the sake of this example) type Q

                    data Q = Q {x'::P, y'::P}
                    instance Predicateable P P where
                        predicate = eq_xy

                Then QuickSpeck can generate laws like:

                    f (y (x' q)) = g (x (y' q))

                which would correspond to:

                    (p a y) && (p x a) => f y = g x

                N-ary Q-types would allow for the same variable to exist in several different predicates,
                creating a conjunction of N terms.

                Furthermore it is conceivable that the Q type does not have to be predicateable over equality.
                Any relation between terms could be used.

            *: FE deals "well" with the conjunction of predicates: (But it is a very hard problem!)
                
                P x && Q x => x <*> y = ...
                gets encoded as
                ((Q'. P') x) <*> y = ...
                where Q' and P' are the function encodings of P and Q.
                However one would need to be very carefull when construction the functions
                Q' and P'. To see an example of how difficult this is notice:
                    
                    Q = not . null
                    P = sorted

                The naive implementation of Q' and P' would be:

                    Q' = whenNotNull
                    whenNotNull [] = [x] -- for some "representative" x
                    whenNotNull xs = xs

                    P' = whenSorted
                    whenSorted xs 
                        | isSorted xs = xs
                        | otherwise = []

                Which is completely fine (when considering only sorted and (not . null)).

                The problem is, what if we were to choose whenNotNull [] = [2, 1].
                Now we have whenSorted . whenNotNull /= whenNotNull . whenSorted.
                Also, the result isnt sorted in the second example.

                This is not a problem with this example, as [2, 1] is a truly bad choice of 
                representative. But if we have something like:

                    allNumbersInListLessThanZero

                    and

                    allNumersInListGreaterThanZeroOrZero

                Now we don't have any implementation of whenNotNull that does not exclude
                one predicate or the other.

                One approach for solving this problem would be to construct functions from all predicate functions
                where the predicate always holds. For an instance:

                    allNumbersInListLessThanZero_and_notNull
                
                This is kind of fine. But we now have an explosion of the size of the signature.

                In conclusion, the composition of these predicate functions does not work as a solution
                to the problem of conjunction. The alternative, to introduce some "power-set" of functions
                and construct additional functions from that set solves the problem of conjunction. 

        -- Soundness -- 
            FE risks losing soundness as predicates which rarely hold will be replaced by their
            "representative". As an example consider "reverseSortedAndLongerThan1000" for lists (this is a stupid example I know),
            this predicate will very rarely hold and if the representative is [] then maybe we discover laws about
            [] that are not about reverseSorted lists. The solution to this is "more testing", maybe...

        -- Transforms -- 
            FE can potentially be more powerfull than TE, as an example it is capable of expressing:
                
                sorted (reverse xs) => ... xs ... (reverse xs) ...

            through equations like:

                ... xs ... (whenSorted (reverse xs)) 

            However this can also be expressed in TE, but we need to change the type 
            so that it generates the transformed data and the other data at the same time.
            This way it would be accesed in this way:

                (x p) (xt p)

            Where (x p) would give the normal data and (xt p) would give the transformed data.

            This would however risk giving us annoying transform-types like:
                
                (xt p) == reverse . reverse 

            To this end it would now be usefull to run QuickSpec on the signature without the 
            predicate types in it at first (maybe with some ad-hoc FE to "substitute" TE) and
            try to prove the equality of transforms.

            An advantage of FE here is clearly the fact that run-time generation (by QuickSpec)
            is a "solved" problem while a TE solution would require us to do something more 
            radical, like introduce a theorem prover at compile time (if we assume that
            the TE types are generated at compile time by template haskell). However this 
            theorem prover may not need to be so complex or general.

            Transforms are only interesting if the equations contain both x and the transform of x.
            Unless the transform significantly alters the structure of the expression, in a way which
            would be quantifiable by some predicate. However, then it would be more interesting to 
            just have the predicate type with that predicate.

        -- Completeness --
            In order to discuss completeness with regards to expressions that do involve implications
            it would be usefull to consider the increase in terms size needed to generate an expression
            on the form:

                P x y ... => E_z[x, y, ... ]

            Where E_z[x, y, ... ] is any equation that would have been considered by old QuickSpec for a given 
            term size z.

            Neither strategy negatively impacts completeness for expressions not involving
            implications as any equations which would be generated
            without FE or TE will still be generated with FE or TE in place. Both methods simply add
            to the existing coverage of QuickSpec. 

            For TE the impact on completeness is linear by a factor 1 in the number of variable occurances in E_z.
            This is because any variable i in E_z could be replaced by (x p) where p is a predicate and x
            is a variable in that predicate. This however is only true for predicate types. For Q-types
            the size increase is a factor 2 in the number of variable occurances in E_z. However, this factor 2 can 
            be reduced to 1 if the access functions from Q-types to the variable types are combined.

            For FE the impact on completeness is dependent on the implementation. It is possible to make the overhead
            linear by a factor 1 in the number of variable occurances in E_z. This is done by having multiple when-functions
            per predicate like so: 
                
                whenP :: (a, b) -> (a, b)

                fstwhenP = fst . whenP
                sndwhenP = snd . whenP

    +: Automatic generation of TE types from given predicates:

        We find that the predicate (sorted :: (Ord a) => [a] -> Bool) can be replaced by a type for sorted lists.

        In fact any unary predicate over some type T:
            
            predicate :: T -> Bool

        Can be modelled as a type:

            data Predicate = Predicate T

            instance Arbitrary where
                arbitrary = fmap Predicate $ arbitrary `suchThat` predicate

        This gives us a conversion from unary FE to unary TE.

        Similary for a binary predicate over any two types T and T':

            predicate :: T -> T' -> Bool

        Can be modelled as the type:

            data Predicate = Predicate T T'

            instance Arbitrary Predicate where
                arbitrary = do
                                (t, t') <- suchThat arbitrary (\(x, y) -> p x y)
                                return (Predicate t t')

        It is important to note that this construction allows encoding of a predicate as a type, in the sense that
        it let's us constuct propositions like P(x) -> E, or !P(x) -> E, where E is an expression (or in the case of
        quickspec an equality). However, it does not let us discover neat laws about the predicate.

        More generally what we can do is something hacky like this:

            class Predicatable a where
                getPredicate :: a -> Bool
            
            predicate :: A -> Bool

            instance Predicatable A where
                getPredicate = predicate

        Now we can automagically derive:

            newtype Predicate a = P a

            instance (Predicatable a, Arbitrary a) => Arbitrary (Predicate a) where
                arbitrary = return . P =<< arbitrary `suchThat` getPredicate

        An example of this is in the derived_predicate demo.

        Even more generally, using template haskell, we can generate these instances for any type.

    +: List of topics:

        *: TE
        
        *: FE

        *: Automatic generation

        *: Conjunction (disjunction)

        *: Transforms

        *: Efficiency

        *: Soudness

        *: Conclusion 

-- Methodology --

    *: Methodology for comparison of FE and TE 
        There are several qualities by which we measure the performance of FE and TE.
        Some of the things discussed in the section above are:

            ~ Efficiency
            ~ Soundness
            ~ Completeness
            ~ Power, i.e. Conjunction and Transforms
            ~ Generality

        These qualities are usefull and relevant as they influence 
        the usefullness of QuickSpec as a component in HipSpec and
        as a stand-alone tool:

            +: Power
            The power of QuickSpec directly increases the power of any system that uses
            QuickSpec.

            +: Efficiency 
            Efficiency is highly relevant when working with intractable problems like
            the ones QuickSpec encounters.

            +: Soundness
            Soundness is a big issue, it can directly influence the efficiency of systems that use 
            QuickSpec. Soundness is also relevant for anyone who is using QuickSpec to explore
            a set of functions (like in the case studies in the papers).

            +: Generality
            Generality is important as it can help write automated tools that incorporate QuickSpec.
            Without a general method for finding FE or TE representations of predicates
            it is difficult to imagine an automated tool that uses predicates in QuickSpec extensively.

            +: Completeness
            Completeness is of interest for the reason pointed out in the first paper on QuickSpec that
            missing equations teaches the user of QuickSpec as much about the systems as equations which are
            present. For this reason the higher the degree of completeness the higher the usefullness
            of QuickSpec as a stand-alone tool. It can be argued that completeness is not as important from an
            integration into other systems point of view as those systems can be left to "fill in the blanks".
            However, if QuickSpec is incomplete then it also directly loses power as a sub-system.

        There are factors and qualities by which one could compare FE and TE which we have
        not explored:

            ~Existing support in QuickSpec
            ~Ease of implementation
